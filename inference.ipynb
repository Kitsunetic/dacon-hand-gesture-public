{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5b0416-2d26-406e-9da9-c86a1eacf269",
   "metadata": {},
   "source": [
    "# 1. Prerequisites\n",
    "\n",
    "## 1-1. Python Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9cd5cc-01c8-4d36-a4de-89407acf50cc",
   "metadata": {},
   "source": [
    "- Albumentations\n",
    "- opencv-python\n",
    "- imageio\n",
    "- numpy\n",
    "- pandas\n",
    "- timm\n",
    "- torch==1.7.0 with cuda toolkit 11.2.2, cudnn8\n",
    "- pyaml\n",
    "- adabelief_pytorch\n",
    "- scikit-learn\n",
    "- tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd43efe-5c1d-4f1a-bee6-dc680614a9b7",
   "metadata": {},
   "source": [
    "## 1-2. Download Pre-trained Weights\n",
    "\n",
    "```bash\n",
    "wget -i \"pretrained_weights.txt\" -P results\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7679173c-1b34-4b45-a663-57818f8d02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from multiprocessing import Pool\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "from typing import Any, Tuple, List\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "from adabelief_pytorch import AdaBelief\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from timm.models.layers import Conv2dSame\n",
    "from timm.models.nfnet import ScaledStdConv2dSame\n",
    "from torch import Tensor\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9040599-d5e1-4f03-a3a6-3dbb9ddb63f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from const.flip import id_flip\n",
    "from const.label_names import id_to_label, label_names\n",
    "from utils import AverageMeter, CustomLogger, make_result_dir, seed_everything, tqdm_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f3ecba-26e1-43df-b50f-0a902939317a",
   "metadata": {},
   "source": [
    "# 1. Dataset\n",
    "\n",
    "The original dataset is located in `./data/ori`.\n",
    "And I will make new dataset by cropping the original dataset and it will be located in `./data/crop512_9`.\n",
    "\n",
    "The new dataset contains both `*.png` and `*.pth` files.\n",
    "But the `*.pth` files are not used in this code, so you can just ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc05cbe1-eb01-4188-8c20-49a98f41943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsize = (512, 512)\n",
    "crop_padding = 120\n",
    "ratio_limit = 1.2\n",
    "seq_len = 5\n",
    "\n",
    "# data numbers where its keypoints contains error\n",
    "wrong_data = [312, 317, 318, 327, 340, 343, 475, 543, 619, 622, 750, 746]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a11e722c-c116-41ed-a62f-36a639b9254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406]).reshape(1, 1, 3)\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225]).reshape(1, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1488590-421c-4611-9431-b5572678fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"./data/crop512_9\")\n",
    "if out_dir.exists():\n",
    "    shutil.rmtree(out_dir)\n",
    "\n",
    "train_out_dir = out_dir / \"train\"\n",
    "test_out_dir = out_dir / \"test\"\n",
    "train_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "test_out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daba193a-8187-4d9e-bf29-bdac9de9c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_resize(im, bbox, dsize, ratio_limit):\n",
    "    \"\"\"resize while keep aspect ratio\"\"\"\n",
    "    # bbox (x1, y1, x2, y2)\n",
    "    # dsize (w, h)\n",
    "    # ratio_limit: float\n",
    "\n",
    "    w = bbox[2] - bbox[0]\n",
    "    h = bbox[3] - bbox[1]\n",
    "\n",
    "    if h == w:\n",
    "        return cv2.resize(im[bbox[1] : bbox[3], bbox[0] : bbox[2]], dsize)\n",
    "\n",
    "    long = h > w\n",
    "    a, b = (h, w) if long else (w, h)\n",
    "    ratio = a / b\n",
    "\n",
    "    if ratio <= ratio_limit:\n",
    "        return cv2.resize(im[bbox[1] : bbox[3], bbox[0] : bbox[2]], dsize)\n",
    "\n",
    "    e, f, g = (bbox[0], bbox[2], im.shape[1]) if long else (bbox[1], bbox[3], im.shape[0])\n",
    "\n",
    "    db = int(a / ratio_limit)\n",
    "    c = db - b\n",
    "    e -= math.ceil(c / 2)\n",
    "    f += math.floor(c / 2)\n",
    "\n",
    "    if e < 0:\n",
    "        f += -e\n",
    "        e = 0\n",
    "    elif f > g:\n",
    "        e -= f - g\n",
    "        f = g\n",
    "\n",
    "    e = max(0, e)\n",
    "    f = min(f, g)\n",
    "\n",
    "    if long:\n",
    "        bbox[0], bbox[2] = e, f\n",
    "    else:\n",
    "        bbox[1], bbox[3] = e, f\n",
    "    fb = f - e\n",
    "\n",
    "    return cv2.resize(im[bbox[1] : bbox[3], bbox[0] : bbox[2]], dsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ca17b8b-2ae1-4c27-9c60-ff73f65450ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bbox(im, u):\n",
    "    \"\"\"\n",
    "    refer to 게으름뱅이 code share:\n",
    "        https://dacon.io/competitions/official/235805/codeshare/3373?page=1&dtype=recent\n",
    "    \"\"\"\n",
    "    mask = (im == [255, 0, 0]).all(axis=-1) | (im == [0, 255, 0]).all(axis=-1)\n",
    "\n",
    "    pos = np.stack(mask.nonzero())\n",
    "    bbox = np.round(\n",
    "        np.array(\n",
    "            (\n",
    "                np.clip(pos[1, :].min() - u, 0, 1920),\n",
    "                np.clip(pos[0, :].min() - u, 0, 1920),\n",
    "                np.clip(pos[1, :].max() + u, 0, 1920),\n",
    "                np.clip(pos[0, :].max() + u, 0, 1920),\n",
    "            ),\n",
    "            dtype=np.float64,\n",
    "        )\n",
    "    ).astype(np.int64)\n",
    "\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2adafa88-dfd8-4b52-a863-08d6d8a4a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(impath: Path, keypoints: np.ndarray):\n",
    "    im = imageio.imread(impath)\n",
    "\n",
    "    # crop\n",
    "    u = crop_padding\n",
    "\n",
    "    if int(impath.parent.name) in wrong_data:\n",
    "        bbox = find_bbox(im, u)\n",
    "    else:\n",
    "        v = keypoints\n",
    "        bbox = np.round(\n",
    "            np.array(\n",
    "                (\n",
    "                    np.clip(v[:, 0].min() - u, 0, 1920),\n",
    "                    np.clip(v[:, 1].min() - u, 0, 1080),\n",
    "                    np.clip(v[:, 0].max() + u, 0, 1920),\n",
    "                    np.clip(v[:, 1].max() + u, 0, 1080),\n",
    "                ),\n",
    "                dtype=np.float32,\n",
    "            )\n",
    "        ).astype(np.int64)\n",
    "\n",
    "    im = elastic_resize(im, bbox, dsize, ratio_limit)\n",
    "\n",
    "    # standardization\n",
    "    im2 = (im.astype(np.float32) / 255.0 - imagenet_mean) / imagenet_std\n",
    "    im2 = torch.from_numpy(im2).permute(2, 0, 1).type(torch.float32)\n",
    "\n",
    "    return im, im2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa39ee4a-cd34-4e69-9178-52a6a555fc8e",
   "metadata": {},
   "source": [
    "## 1-1. Generate Training Dataset\n",
    "\n",
    "The training image file names are following this format `{dir index}_{image index}_{label index}.png`, e.g. `001_02_003.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b61152fb-09f7-429d-919e-225e79b68676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dir_train(dirpath: Path):\n",
    "    with open(dirpath / f\"{dirpath.name}.json\") as f:\n",
    "        j = json.load(f)\n",
    "\n",
    "    diridx = int(dirpath.name)\n",
    "\n",
    "    label = id_to_label[j[\"action\"][0]]\n",
    "    label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    for i, annot in enumerate(j[\"annotations\"]):\n",
    "        impath = dirpath / f\"{i}.png\"\n",
    "        im_org, im = process_image(impath, np.array(annot[\"data\"]))\n",
    "\n",
    "        # save image\n",
    "        fname = f\"{diridx:03d}_{i:02d}_{label.item():03d}\"\n",
    "        imageio.imwrite(train_out_dir / (fname + \".png\"), im_org)\n",
    "        torch.save(im, train_out_dir / (fname + \".pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63a9c7c9-d849-4619-aba2-4bba3c4e4a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = sorted(list(Path(\"./data/ori/train\").glob(\"*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08b529e0-b611-4dde-98b7-95f1d5399aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dirs)  # 649"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e503c00-cf77-4e1c-bc5f-a10d00eb42e7",
   "metadata": {},
   "source": [
    "There are 649 training directories containing multiple images.\n",
    "I applied parallelism because processing all of these data takes too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "400054e0-f964-4ab8-b830-958b774bd1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 649/649 [12:01<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "with Pool() as pool:\n",
    "    with tqdm(total=len(dirs), ncols=100, file=sys.stdout) as t:\n",
    "        for _ in pool.imap_unordered(process_dir_train, dirs):\n",
    "            t.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b9c7e8-8f9d-4a25-a6d4-cd07752d00ab",
   "metadata": {},
   "source": [
    "## 1-2. Generate Test Dataset\n",
    "\n",
    "The test image file names are following this format `{dir index}_{image index}_{label index}.png`, e.g. `001_02.png`.\n",
    "It's basically similar to training dataset but there is no label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59cc5d9d-cead-4335-ad59-86ad88c4876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dir_test(dirpath: Path):\n",
    "    with open(dirpath / f\"{dirpath.name}.json\") as f:\n",
    "        j = json.load(f)\n",
    "\n",
    "    diridx = int(dirpath.name)\n",
    "\n",
    "    for i, annot in enumerate(j[\"annotations\"]):\n",
    "        impath = dirpath / f\"{i}.png\"\n",
    "        im_org, im = process_image(impath, np.array(annot[\"data\"]))\n",
    "\n",
    "        # save image\n",
    "        fname = f\"{diridx:03d}_{i:02d}\"\n",
    "        imageio.imwrite(test_out_dir / (fname + \".png\"), im_org)\n",
    "        torch.save(im, test_out_dir / (fname + \".pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59bb663b-9dcf-4310-90e9-bc1aa1ecd409",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = sorted(list(Path(\"./data/ori/test\").glob(\"*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a529fe6a-ee9b-4989-8c04-bd238443e301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dirs)  # 217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f0e795b-0f15-4a13-b004-2d6053cfed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 217/217 [04:15<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "with Pool() as pool:\n",
    "    with tqdm(total=len(dirs), ncols=100, file=sys.stdout) as t:\n",
    "        for _ in pool.imap_unordered(process_dir_test, dirs):\n",
    "            t.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e447f88-37f5-422c-b940-f6ecf9386b66",
   "metadata": {},
   "source": [
    "# 2. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c7cb820-e15d-4df6-b9a5-1ad3c1b46e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import Config, Net, GestureDataset, DATA_DIR, DATA_NAME, N_CLASSES, FileLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "375fb4e6-5943-49a2-8765-e3cd8bcf64a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_dataset(config: Config):\n",
    "    files_test = sorted(list((DATA_DIR / DATA_NAME / \"test\").glob(\"*.png\")))\n",
    "    fileloader = FileLoader(in_memory=config.in_memory, files=files_test)\n",
    "\n",
    "    data = defaultdict(list)\n",
    "    for file in files_test:\n",
    "        # test filename: {diridx:3d}_{fileidx:2d}\n",
    "        diridx = int(file.stem[:3])\n",
    "        data[diridx].append(file)\n",
    "\n",
    "    items_test = []\n",
    "    for diridx in data:\n",
    "        if len(data[diridx]) > config.len_sequence:\n",
    "            for i in range(len(data[diridx]) - config.len_sequence):\n",
    "                items_test.append((data[diridx][i : i + config.len_sequence], diridx))\n",
    "        elif len(data[diridx]) == config.len_sequence:\n",
    "            items_test.append((data[diridx], diridx))\n",
    "        else:\n",
    "            fake = [data[diridx][-1] for _ in range(config.len_sequence - len(data[diridx]))]\n",
    "            items_test.append((data[diridx] + fake, diridx))\n",
    "\n",
    "    dl_kwargs = dict(batch_size=config.batch_size, num_workers=config.num_workers, pin_memory=True)\n",
    "    ds_test = GestureDataset(items_test, fileloader=fileloader, augmentation=False)\n",
    "    dl_test = DataLoader(ds_test, **dl_kwargs, shuffle=False)\n",
    "\n",
    "    return dl_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b7ecdeb-0be2-48b9-9dc1-5313b4525884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(exp_num='001', ver_num=None, result_dir_root=PosixPath('results/exp'), result_dir=None, seed=1, debug=False, model_name='tf_efficientnetv2_l_in21ft1k', checkpoint_path=None, len_sequence=5, pretrained=True, criterion='focal', num_folds=5, fold=1, epochs=100, finetune=True, finetune_step1_epochs=2, finetune_step2_epochs=4, optimizer_name='AdaBelief', lr=0.001, weight_decay=0.01, scheduler=<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, sam=True, look_ahead=True, look_ahead_k=5, look_ahead_alpha=0.5, batch_size=18, num_workers=6, cleared_image=False, in_memory=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config(\n",
    "    debug=False,\n",
    "    finetune=True,\n",
    "    model_name=\"tf_efficientnetv2_l_in21ft1k\",\n",
    "    batch_size=18,\n",
    "    sam=True,\n",
    "    pretrained=True,\n",
    "    optimizer_name=\"AdaBelief\",\n",
    "    fold=1,\n",
    "    seed=1,\n",
    "    num_workers=6,\n",
    "    in_memory=True,\n",
    "    lr=1e-3,\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67669d6d-2bd9-4944-bc0e-16e1a9947165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-memory loading...: 100%|████████████████████████████████████| 2038/2038 [00:18<00:00, 108.37it/s]\n"
     ]
    }
   ],
   "source": [
    "dl = make_test_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bde8576f-7903-4710-a0e0-c345cc96ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(\n",
    "    name=config.model_name,\n",
    "    n_classes=N_CLASSES,\n",
    "    pretrained=False,\n",
    "    len_sequence=config.len_sequence,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed9e17d2-5a55-46dd-9c02-844a6561894a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f41bc1aef50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71ee5b15-150d-4d11-af4f-78df2b5e9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(ckpt_path, ver_idx):\n",
    "    # print('Load checkpoint:', ckpt_path)\n",
    "    model.load_state_dict(torch.load(ckpt_path))\n",
    "    model.eval()\n",
    "\n",
    "    ret = defaultdict(list)\n",
    "    with tqdm(total=len(dl.dataset), ncols=100, file=sys.stdout, desc=f\"submission{ver_idx:02d}\") as t:\n",
    "        for images, diridxes in dl:\n",
    "            logits = model(images.cuda()).cpu()\n",
    "\n",
    "            for logit, diridx in zip(logits, diridxes):\n",
    "                ret[diridx.item()].append(logit)\n",
    "\n",
    "                t.update()\n",
    "\n",
    "    out_ms = defaultdict(list)\n",
    "    for diridx, logits in ret.items():\n",
    "        out_ms[\"Image_Path\"].append(f\"./test\\\\{diridx}\")\n",
    "\n",
    "        logits = torch.stack(logits)\n",
    "        logit_ms = logits.mean(dim=0).softmax(dim=0)\n",
    "\n",
    "        for k in range(196):\n",
    "            if k in id_to_label:\n",
    "                out_ms[f\"Label_{k}\"].append(logit_ms[id_to_label[k]].item())\n",
    "\n",
    "    df_ms = pd.DataFrame(out_ms)\n",
    "\n",
    "    out_df_path = Path(f\"./results/submission/{ver_idx:02d}.csv\")\n",
    "    out_df_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    # print(\"Write result to\", out_df_path % \"_\")\n",
    "    df_ms.to_csv(out_df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "992c7e81-b193-4152-b0a2-f5e25181229d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission00: 100%|███████████████████████████████████████████████| 959/959 [00:37<00:00, 25.42it/s]\n",
      "submission01: 100%|███████████████████████████████████████████████| 959/959 [00:38<00:00, 25.15it/s]\n",
      "submission02: 100%|███████████████████████████████████████████████| 959/959 [00:37<00:00, 25.78it/s]\n",
      "submission03: 100%|███████████████████████████████████████████████| 959/959 [00:37<00:00, 25.35it/s]\n",
      "submission04: 100%|███████████████████████████████████████████████| 959/959 [00:37<00:00, 25.39it/s]\n",
      "submission05: 100%|███████████████████████████████████████████████| 959/959 [00:38<00:00, 25.17it/s]\n",
      "submission06: 100%|███████████████████████████████████████████████| 959/959 [00:38<00:00, 25.08it/s]\n",
      "submission07: 100%|███████████████████████████████████████████████| 959/959 [00:37<00:00, 25.62it/s]\n",
      "submission08: 100%|███████████████████████████████████████████████| 959/959 [00:38<00:00, 25.14it/s]\n",
      "submission09: 100%|███████████████████████████████████████████████| 959/959 [00:37<00:00, 25.43it/s]\n",
      "submission10: 100%|███████████████████████████████████████████████| 959/959 [00:38<00:00, 24.87it/s]\n",
      "submission11: 100%|███████████████████████████████████████████████| 959/959 [00:38<00:00, 24.97it/s]\n",
      "submission12: 100%|███████████████████████████████████████████████| 959/959 [00:38<00:00, 24.98it/s]\n",
      "submission13: 100%|███████████████████████████████████████████████| 959/959 [00:38<00:00, 25.15it/s]\n",
      "submission14: 100%|███████████████████████████████████████████████| 959/959 [00:38<00:00, 25.19it/s]\n",
      "submission15: 100%|███████████████████████████████████████████████| 959/959 [00:37<00:00, 25.52it/s]\n",
      "submission16: 100%|███████████████████████████████████████████████| 959/959 [00:38<00:00, 24.92it/s]\n",
      "CPU times: user 10min 22s, sys: 1min 52s, total: 12min 14s\n",
      "Wall time: 11min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, ckpt_path in enumerate(sorted(list(Path('results').glob('exp*.pth')))):\n",
    "    submit(ckpt_path,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c84ee12-25b1-4184-8773-b2df94b6e570",
   "metadata": {},
   "source": [
    "# 3. Ensemble Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a57a1b70-0c0e-4257-b416-72b449133c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(file) for file in list(Path(\"results/submission\").glob(\"*.csv\"))]\n",
    "rets = [df.to_numpy()[:, 1:].astype(np.float64) for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62429b26-1387-4d48-a3a1-bfd8f7334ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 217, 157)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rets = np.stack(rets)\n",
    "rets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cda9705a-1e01-4024-96d8-31d388593082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple mean ensemble\n",
    "ret = rets.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62b90d63-2778-4789-8cba-9c37a23bdf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = {\"Image_Path\": dfs[0][\"Image_Path\"]}\n",
    "for i, col in enumerate(dfs[0].columns[1:]):\n",
    "    new_df[col] = ret[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d16ed16-b51f-4608-a358-d8c994ff14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e08b0cc-6f1d-4a06-893d-da85574a4c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "      <th>Label_5</th>\n",
       "      <th>Label_6</th>\n",
       "      <th>Label_7</th>\n",
       "      <th>Label_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Label_177</th>\n",
       "      <th>Label_186</th>\n",
       "      <th>Label_188</th>\n",
       "      <th>Label_189</th>\n",
       "      <th>Label_190</th>\n",
       "      <th>Label_191</th>\n",
       "      <th>Label_192</th>\n",
       "      <th>Label_193</th>\n",
       "      <th>Label_194</th>\n",
       "      <th>Label_195</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./test\\649</td>\n",
       "      <td>0.747927</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.082456</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.136778e-05</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>6.955291e-06</td>\n",
       "      <td>1.396406e-05</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>7.852546e-06</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./test\\650</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.963366e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.344761e-07</td>\n",
       "      <td>8.749638e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.305973e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./test\\651</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.349364e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.148435e-06</td>\n",
       "      <td>1.000146e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.308252e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./test\\652</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.271714e-06</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7.670794e-07</td>\n",
       "      <td>6.080505e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.790643e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./test\\653</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.861358e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.401509e-06</td>\n",
       "      <td>1.128680e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.290545e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>./test\\861</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>1.938008e-04</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>1.460377e-04</td>\n",
       "      <td>1.855239e-04</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.985866</td>\n",
       "      <td>5.399363e-04</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>./test\\862</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>1.985968e-03</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>6.577956e-04</td>\n",
       "      <td>1.348196e-03</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>9.789394e-01</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>./test\\863</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>6.330425e-05</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>9.724208e-05</td>\n",
       "      <td>8.434278e-05</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>3.722209e-04</td>\n",
       "      <td>0.992364</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>./test\\864</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>1.778930e-04</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>1.845065e-04</td>\n",
       "      <td>2.580232e-04</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>3.127511e-03</td>\n",
       "      <td>0.978138</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>./test\\865</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>1.151169e-04</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>8.758349e-05</td>\n",
       "      <td>2.240052e-05</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>3.310557e-04</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.985317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image_Path   Label_0   Label_1   Label_2   Label_3   Label_4   Label_5  \\\n",
       "0    ./test\\649  0.747927  0.001944  0.000419  0.000253  0.000087  0.002656   \n",
       "1    ./test\\650  0.000736  0.000008  0.000008  0.000012  0.000003  0.000005   \n",
       "2    ./test\\651  0.000007  0.000708  0.000026  0.000016  0.000007  0.000005   \n",
       "3    ./test\\652  0.000006  0.000677  0.000021  0.000014  0.000003  0.000002   \n",
       "4    ./test\\653  0.000009  0.000020  0.000751  0.000092  0.000011  0.000003   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "212  ./test\\861  0.000010  0.000019  0.000006  0.000015  0.000010  0.000034   \n",
       "213  ./test\\862  0.000015  0.000024  0.000024  0.000041  0.000015  0.000025   \n",
       "214  ./test\\863  0.000004  0.000004  0.000007  0.000010  0.000013  0.000009   \n",
       "215  ./test\\864  0.000007  0.000017  0.000017  0.000030  0.000039  0.000028   \n",
       "216  ./test\\865  0.000006  0.000035  0.000012  0.000017  0.000005  0.000013   \n",
       "\n",
       "      Label_6   Label_7   Label_8  ...  Label_177     Label_186  Label_188  \\\n",
       "0    0.082456  0.000060  0.000034  ...   0.000017  1.136778e-05   0.000019   \n",
       "1    0.000092  0.000001  0.000003  ...   0.000002  7.963366e-07   0.000002   \n",
       "2    0.000006  0.000087  0.000005  ...   0.000003  2.349364e-06   0.000002   \n",
       "3    0.000002  0.000051  0.000003  ...   0.000002  1.271714e-06   0.000001   \n",
       "4    0.000004  0.000003  0.000076  ...   0.000001  9.861358e-07   0.000001   \n",
       "..        ...       ...       ...  ...        ...           ...        ...   \n",
       "212  0.000013  0.000009  0.000008  ...   0.000095  1.938008e-04   0.001260   \n",
       "213  0.000022  0.000022  0.000035  ...   0.002363  1.985968e-03   0.000239   \n",
       "214  0.000009  0.000005  0.000009  ...   0.000665  6.330425e-05   0.000012   \n",
       "215  0.000021  0.000022  0.000031  ...   0.005940  1.778930e-04   0.000061   \n",
       "216  0.000009  0.000016  0.000013  ...   0.000181  1.151169e-04   0.000781   \n",
       "\n",
       "        Label_189     Label_190  Label_191  Label_192     Label_193  \\\n",
       "0    6.955291e-06  1.396406e-05   0.000038   0.000045  7.852546e-06   \n",
       "1    9.344761e-07  8.749638e-07   0.000003   0.000002  2.305973e-06   \n",
       "2    1.148435e-06  1.000146e-06   0.000002   0.000001  1.308252e-06   \n",
       "3    7.670794e-07  6.080505e-07   0.000002   0.000001  9.790643e-07   \n",
       "4    1.401509e-06  1.128680e-06   0.000002   0.000001  1.290545e-06   \n",
       "..            ...           ...        ...        ...           ...   \n",
       "212  1.460377e-04  1.855239e-04   0.003821   0.985866  5.399363e-04   \n",
       "213  6.577956e-04  1.348196e-03   0.000101   0.000368  9.789394e-01   \n",
       "214  9.724208e-05  8.434278e-05   0.000011   0.000176  3.722209e-04   \n",
       "215  1.845065e-04  2.580232e-04   0.000036   0.000862  3.127511e-03   \n",
       "216  8.758349e-05  2.240052e-05   0.003205   0.000496  3.310557e-04   \n",
       "\n",
       "     Label_194  Label_195  \n",
       "0     0.000036   0.000012  \n",
       "1     0.000002   0.000002  \n",
       "2     0.000004   0.000003  \n",
       "3     0.000002   0.000002  \n",
       "4     0.000002   0.000001  \n",
       "..         ...        ...  \n",
       "212   0.000201   0.000592  \n",
       "213   0.000721   0.000451  \n",
       "214   0.992364   0.000033  \n",
       "215   0.978138   0.000100  \n",
       "216   0.000154   0.985317  \n",
       "\n",
       "[217 rows x 158 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b58a42ff-a445-4fd3-92ce-9914cf6569d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"results/ensemble.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2d569-0bf6-447b-a945-59ad02e6dd68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
